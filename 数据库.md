# 数据库常见问题汇总    
## 目录
[通用](https://github.com/LuciferLau/Skills/blob/master/%E6%95%B0%E6%8D%AE%E5%BA%93.md#%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%9A%E7%94%A8)  
[MySQL](https://github.com/LuciferLau/Skills/blob/master/%E6%95%B0%E6%8D%AE%E5%BA%93.md#mysql)  
[Redis](https://github.com/LuciferLau/Skills/blob/master/%E6%95%B0%E6%8D%AE%E5%BA%93.md#redis)  

---

## 数据库通用
    • 关系型和非关系型数据库的区别（各自优点）
关系型数据库的代表：MySQL，Oracle存储空间大,，使用关系模式组织数据，使用SQL语言，保证事务的ACID特性，但不容易横向扩展，高并发性能低。  
非关系型数据库代表：Redis，MongoDB存储数据在缓存中，可以本地持久化，执行速度快，适合高并发读写操作，但一般不支持事务的ACID，海量数据情况下效率SAVE效率低。  

    • 常用SQL语句（DDL,DML,DCL,TCL）
数据定义语言（DDL）、 数据操作语言（DML）、数据控制语言（DCL）和事物控制语言（TCL）。  
DDL(data definition language): CREAT/DROP… ;   
DML(data manipulation language): SELECT/UDDATE/INSERT INTO/DELETE ;  
DCL(data control language): GRANT/REVOKE/DENY ;  
TCL(transaction control language): SAVEPOINT/ROLLBACK/COMMIT .  

    • 数据库中join的类型与区别，注意适用场景和sql语句的编写
内连接(inner join)：最普通的连接，只包含两表中匹配的行。  
外连接(outer join)：分为左连接，右连接，全连接。左连接包含左表中所有行和右表中匹配的行；右连接包含右表中所有行和左表中匹配的行；全连接就是包含左右表中所有的行。  
交叉连接(cross join)：两个表求笛卡尔积，数据量大，复杂。  
自然连接(natural join)：也分左右连接，默认全连接，是一种特殊的等值匹配，自动删除重名列。  
自连接(self join)：一个表与自己的镜像进行连接，可以获得意外收获，如公交换乘。  

    • 数据库的索引类型
普通索引（index）：CREATE INDEX index_name ON table_name((列名(长度))；  
唯一索引（unique）：CREATE UNIQUE INDEX idx_name ON tab_name ((列名(长度))；  
全文索引（fulltext）：CREATE FULLTEXT INDEX idx_content ON tab_name(content)；  
主键索引（primary key）：ALTER TABLE ADD PRIMARY KEY(‘column’)；  
组合索引（最左前缀）：ALTER TABLE tab_name ADD INDEX idx_name(字段1,2,3)。  

    • 聚集索引和非聚集索引的区别（叶节点存储内容）
聚焦索引：每个表只能有一个（PK），索引键值逻辑顺序决定对应行的物理顺序，可以包含多个列（组合索引），在范围搜索时高效，因为是按顺序存储的。叶节点是数据节点。  
非聚焦索引：每个表可以有多个，索引键值逻辑顺序与磁盘上行的物理顺序不同，叶节点还是索引节点。  

    • 唯一性索引和主键索引的区别
一个表中唯一索引可以有多个，主键索引只有一个；
主键是一种约束（constraint），唯一索引是一种索引（index）；  
唯一索引允许null，主键not null；  
主键可以成为别的表的FK，唯一索引不行；主键一定是唯一性索引，唯一索引不一定是主键。  

    • 索引的优缺点，什么时候使用索引，什么时候不能使用索引（重点）
优点：索引加快了数据查询的速度。  
缺点：索引需要额外的维护成本，占用磁盘空间，且在频繁增删数据的时候成本会变高。  
在查询数据量大但修改次数少的表的时候应该建立索引。  
在查询数据量小或者需要频繁修改的表的时候不应该给对应的列建立索引。  
![index](https://raw.githubusercontent.com/LuciferLau/Skills/master/pic/index.png)

    • 索引的底层实现（B+树，为何不采用红黑树，B树）
索引的底层实现是B+树。RB树频繁左右旋转，浪费时间，而且是二叉树，查询效率较低；B树不如B+树，叶子节点没有用指针连在一起。B+树叶子结点形成有序链表，查询更快；相较于B树，B+树每次查询都要查询到叶子节点，更稳定，且节点的元素更多，磁盘IO更少。  

    • B树和B+树具体实现
https://blog.csdn.net/u011109881/article/details/80344606
   
    • 索引最左前缀问题
在使用组合索引的时候，假设有index（A，B，C），其实是生成了三个索引  
①index（A，B，C）②index（A，B）③index（A），在查询语句中只有BC的时候用不上这个索引，where子句中最频繁的应该放在组合索引最左边。  

    • 数据库中事务的ACID（四大特性都要能够举例说明，理解透彻，比如原子性和一致性的关联，隔离性不好会出现的问题）
A（atomicity）原子性：事务对数据库的操作要么全部成功，要么全部失败。  
C（consistency）一致性：事务执行前后数据完整性保持一致。  
I（isolation）隔离性：多用户并发执行事务时，每个事务隔离，互相不影响。  
D（durability）持久性：事务只要提交，对数据库的影响是持久的，  

    • 数据库隔离性设置不同会出现的问题（脏读、不可重复读、丢失修改、幻读）
脏读：读取到未提交（commit）的数据，如果事务回滚，那么读取到的数据有误。  
不可重复读：读取了前面事务提交的更新数据，和之前读取的结果不一样。（行级锁可破）  
幻读：读取了前面事务提交的新增数据，和之前结果不一样。（表级锁可破）  
丢失修改：两个事务同时修改同一个表项，可能会相互覆盖，其中一放丢失更新。 
![isolation](https://raw.githubusercontent.com/LuciferLau/Skills/master/pic/dbisolation.png)

    • 数据库的范式
INF：要求属性（列）的原子性，不可再分。  
2NF：要求记录的唯一性，记录有唯一值，即实体的唯一性。  
3NF：要求字段没有冗余。  

    • 数据的锁的种类，加锁的方式（乐观锁与悲观锁的区别)
数据库层面上看可以分为：共享锁（S），排它锁（X）,更新锁（U）  
程序员角度看可以分为：乐观锁（optimistic lock），悲观锁（pessimistic lock）。  
S：读锁，类似读者写者问题，可以多人同时上S锁，但只要有S就不能上X锁。  
X：写锁，上了X锁后，没别人能够操作数据直到事务完成。  
U：更新锁，期间可以进行读上S锁，但不能再上X/U锁，写时更新为X锁，完成才释放。  
悲观：觉得别人会来修改你，所以严格排它。乐观：假设别人都不修改你。 

    • 视图的作用与使用方法（如何删除等）
视图是一个虚表，数据库中只存放定义，数据都来源于别的表。  
作用：①可以把常用数据定义为视图，简化操作；②安全性，用户只能查询和修改看到的数据；③独立性，屏蔽了真实的数据表。  
删除：drop view 视图名。  

    • 数据库连接池的作用  
在较为频繁访问数据库的应用中，客户端每次访问都需要与数据库建立连接完成后再断开，这会产生大量的资源消耗。  
使用连接池释放连接后让连接池管理连接，而不是断开连接，这样子可以减少系统的开销，并且连接池中有部分数据可以直接读取，加快响应速度。  

## MySQL
    • Mysql的优化（高频，索引优化，性能优化）
注意什么时候用索引，用什么索引，查询语句怎么写，大量数据时like效率的极低。
    
    • 数据库引擎介绍，Innodb和Myisam的特点与区别
Innodb支持行级锁，支持事务操作，支持外键，批量插入慢。  
Myisam只支持表级锁，不支持事务，外键，支持全文索引，批量插入快，保存了行数。  
 
    • 数据库的隔离级别，Mysql和Oracle的隔离级别分别是什么
从低到高：读未提交，读已提交，可重复读，串行化。select @@tx_isolation;（查询语句）  
Mysql默认是可重复度，Oracle只支持读已提交和串行化，默认是读已提交。  

    • Mysql的表空间方式，各自特点
http://blog.itpub.net/15498/viewspace-2124040/  

## Redis
    • 基本数据类型
类型 | 底层实现 | 备注
-- | -- | --
String | SDS(simple dynamic string)简单动态字符串 | 线程安全，O(1)获取长度
List | 双向链表/压缩链表(每个元素 <64 Byte 且 总元素 <512 个) | 3.2版本后统一替换成 QuickList 
Hash | 哈希表/压缩列表(每个元素 <64 Byte 且 总元素 <512 个) | 7.0后压缩列表由 ListPack 代替
Set | 哈希表/整数集合(总元素 <512 个) | -
Zset | 跳表/压缩列表(每个元素 <64 Byte 且 总元素 <128 个) | 7.0后压缩列表由 ListPack 代替  

    • 基本数据类型对应的方法
> 这里方法中的空格只是便于阅读，实际不存在  

String：SDS可能是 raw/embstr 编码，其余的则是 int 编码  

方法 | 备注
-- | -- 
[STRING]
GET | 获取 k 对应 v
SET | 设置 k 对应 v
M GET | 批量获取 k 对应 v
M SET | 批量设置 k 对应 v
STRLEN | 字符串时，返回 k 对应长度
INCR | 数字时，自增 k
INCRBY | 数字时，增大 k 的值 n
DECR | 数字时，自减 k
DECRBY | 数字时，减小 k 的值 n
DEL | 删除 k
TTL | 获取 k 的剩余时间
EXPIRE | 设置 k 的过期时间
EXISTS | 判断 k 是否存在
SET NX | 和 SET 相同，不存在的时候才插入（NX：not exist）
[LIST]
L PUSH | 插入若干 v 到列表 k 左边
R PUSH | 插入若干 v 到列表 k 右边
L POP | 移除返回列表 k 左边 v
R POP | 移除返回列表 k 右边 v
L RANGE | 返回列表 k 在区间 [s,e] 内的 v
B L POP | 列表 k 左边移除一个 v ，如果没有则阻塞 n 秒
B R POP | 列表 k 右边移除一个 v ，如果没有则阻塞 n 秒
[HASH]
H GET | 获取 k 对应 field 的 v
H SET | 设置 k 对应 field 的 v
HM GET | 批量获取 k 对应 field 的 v
HM SET | 批量设置 k 对应 field 的 v
H DEL | 
H LEN | 返回 k 中 field 数量，即hash中key的数
H GETALL | 返回 k 中所有的 field
H INCRBY | 同上
[SET]
S ADD | 集合 k 中存入 v
S REM | 集合 k 中移除 v
S MEMBERS | 获取集合 k 中所有元素
SCARD | 获取集合 k 中元素个数
S IS MEMBER | 判断 v 是否在集合 k 中
S RAND MEMBER | 从集合 k 中随机选 n 个元素
S POP | 从集合 k 中随机选 n 个元素，并且从集合中删除
S INTER | 求集合 k1 k2 ... kn 的交集
S INTER STORE | 求集合 k1 k2 ... kn 的交集，并存入 dest
S UNION | 求集合 k1 k2 ... kn 的并集
S UNION STORE | 求集合 k1 k2 ... kn 的并集，并存入 dest
S DIFF | 求集合 k1 k2 ... kn 的差集
S DIFF STORE | 求集合 k1 k2 ... kn 的差集，并存入 dest
[ZSET]
Z ADD | 有序集合 k 中加入分为 s 的 v
Z REM | 有序集合 k 中移除 v
Z SCORE | 获取有序集合 k 中 v 的分
ZCARD | 获取有序集合中 v 的个数
Z INCRBY | 给有序集合 k 中的 v 加 s 分
Z RANGE | 获取有序集合 k 中区间 [s,e] 的元素，正序
Z REV RANGE | 获取有序集合 k 中区间 [s,e] 的元素，倒序
Z RANGE BY SCORE | 获取有序集合 k 中分数区间在 [min,max] 的元素
Z RANGE BY LEX | 获取有序集合 k 中分数区间在 [min,max] 的元素，正序，且分数必须相同
Z REV RANGE BY LEX | 获取有序集合 k 中分数区间在 [min,max] 的元素，倒序，且分数必须相同
Z INTER STORE | 交集
Z UNION STORE | 并集
【BitMap】
【HyperLogLog】
【GEO】
【Stream】

    • 单线程模型
主要体现在读写数据的步骤：Client req -> Redis Server write -> Client read 这个步骤是单线程的。  
但实际上还有其它线程，用于关闭文件，AOF刷硬盘，lasyfree线程释放内存，  
因为这些涉及大量I/O的操作会产生大量消耗，如果不异步处理会导致读写阻塞。  

    • 数据持久化
AOF：每一条写操作都向日志文件追加写入该命令，类似mongoDb的oplog  
RDB：将某一时刻的内存数据，以二进制方式写入磁盘，即内存快照  
混合持久化：4.0版本新增，结合2者优势  
> 混合：fork出子进程会先将内存快照以RDB方式写入AOF文件，然后把重写缓冲区里的操作命令以增量方式写入AOF文件。  
结合了二者的优势，保证Redis能快速恢复RDB的数据，也尽量保证了数据的一致性。

AOF选项（conf文件中appendfsync） | 描述
-- | --
Always | 同步写日志，即写命令执行时都写入硬盘日志文件
Everysec | 定时器每秒写1次，最多丢失1s数据
No | 由操作系统决定什么时候写回，危

> AOF日志压缩方式：AOF重写
当AOF文件大小超过一个阈值时，将DB中所有键值对用一条命令写到新AOF文件，然后替换旧的文件。（假定历史操作是无意义的）  
同时设立了重写缓冲区，与AOF普通缓冲区同步追加新命令，避免不一致的情况出现
   
RDB命令 | 描述
-- | --
save | 阻塞主线程
bgsave | 非阻塞，fork出子进程执行，因为写时拷贝，只读操作是不会影响主线程写入数据的

> RDB持久化数据在恢复时，主节点会不会加载过期key，从节点会，但在数据同步时，从服务器的过期key也会被清空，所以无影响

    • Redis集群，分布式事务

- 主从复制【Master Slave】  
一主多从：一台主节点，其它都是从节点  
读写分离：只有主节点可以同时读和写，从节点只能读，同步主节点的写操作命令  
    
主节点选举过程：quorum 建议值为 1/2 的 哨兵数量，结果为偶数时+1，使其成为奇数  
① 首先当然得先把旧主节点干掉，哨兵进行投票，票数大于 quorum 时，主节点被判定为不可达，于是开始选举新的 leader。  
② 候选者可以申请成为leader，给自己投1票；在获得半数票 & 大于quorum 同时达成的条件下就可以成为新leader。  

主节点详细算法：综合 优先级，复制数据offset，ID号大小 这几个指标选出最优从节点  
1、在起从节点时，可以通过配置 slave-priority 来决定从节点优先级；  
2、比较从节点 slave_repl_offset 和 主节点的 master_repl_offset，最接近的优先；(Q：主节点挂了怎么获取？A:INFO replication，获取各从节点的比较就行)  
3、比无可比，就比ID，先到先得。。。  
选出最优从节点后，哨兵会发送 slaveof no one 指令使其升级为主节点  
然后向其余从节点发送 slaveof 改变它们的主节点  
最后向客户端广播主节点变更消息，通过发布/订阅机制实现  
假设旧的主节点还能够重新上线，会对它进行降级，发送 slaveof 命令使其成为从节点  

- 哨兵模式【Sentinel】  
哨兵节点通过心跳保证各服务器正常运行情况，监控主从节点，主节点出现故障时服务不可用时，及时选举出新的主节点
> 哨兵集群：哨兵往往需要 >2 个来避免误判，毕竟哨兵节点的进程可能出问题，所在的机器也可能出现问题   

哨兵中也需要有 leader 来给选举出的新旧主节点/从节点发送命令，所以哨兵也需要有选举机制：  
获胜条件是相同的，过半数票 & 大于等于 quorum 值，哨兵可以自荐，并问其余哨兵是否愿意投票给自己，先到先得  

- 切片集群模式【Cluster】  
如果所有数据都存放在主节点，可能会存在数据量过大，内存不足的问题，这时候就需要 cluster 出马  
TODO  

- 脑裂问题  
简单来说，就是主从结点间网络断连，主节点和客户端正常连接，客户端还在写数据  
其它从节点这时候已经重新选出新的leader了，同时存在2个主节点的情况，叫做脑裂  
在网络异常恢复后，旧的主节点会被降级为从节点，但问题断连期间的命令都没有同步给旧的从节点  
这个时候就会造成数据丢失的异常，称为集群脑裂数据丢失
> 解决脑裂：根据脑裂原因，我们可以禁止客户端向主节点写数据，  
> 通过设置主节点/从节点连接最小值 min-slaves-to-write 和 主从通信延迟最小值 min-slaves-max-lag
    
---

    • 缓存过期删除策略
> 类似内存的页，redis在找不到对应查询值的时候，也会发生类似“缺页”的情况，加载新key的时候，也要将旧的key移除  

缓存策略 | 描述
-- | --
惰性删除 | 在主动访问到key的时候，检查key是否过期，是则移除
定期删除 | 从过期字典（expired dict）中随机抽 20 个key，如果过期key的占比 >25% 则继续抽 20 个循环，否则退出循环

在 Redis 进程运存超过设定值时，会触发内存淘汰策略
内存策略 | 描述
-- | --
noeviction | 对新数据的写入返回错误码，不作内存淘汰回收（3.0版本后默认策略）
volatile-random | 有过期时间的key中，随机淘汰key
volatile-ttl | 有过期时间的key中，优先淘汰即将过期的key
volatile-lru | 有过期时间的key中，淘汰最近最少使用的key（3.0版本前默认策略）
volatile-lfu | 有过期时间的key中，淘汰最近最不常用的的key（4.0版本新增策略）
allkeys-random | 所有key中，随机淘汰key
allkeys-lru | 所有key中，淘汰最近最少使用的key
allkeys-lfu | 所有key中，淘汰最近最不常用的的key（4.0版本新增策略）
> Least Frequently Used 和 Least Recently Used 的唯一区别，LFU新增了 数据被访问次数 这一标准，算是对LRU的优化
    
    • 缓存雪崩/击穿/穿透
雪崩：大量 key 同时过期，导致磁盘db访问量骤增。通过错开过期时间，或者直接不过期来避免  
击穿：一个 key 同时被大量访问，但此key又刚好过期，导致请求直接到了磁盘db。通过加锁限制访问量，或者直接不过期来避免  
穿透：大量查询同时查询不存在的 key，导致性能耗费在无意义的事情上。给不存在的key设置默认值返回，或者判断key是否存在（bloom filter）

    • 热点数据的处理？缓存更新策略
缓存策略一般使用旁路缓存：该策略适合 读多 写少 的场景  
写数据时，先更新db中的值，然后删除Redis中的key  
> 不能先删key再更db，实际中写db的速度远远低于写cache，这个顺序可以降低cache被db旧数据回写的概率（即仍然会发送）  

读数据时，如果发现Redis未命中，就从db读出值，然后更新Redis中key的值  

    • 分库分表，主从复制，读写分离。（没用过读写分离）  
主从复制：Redis2.8前通过 SYNC 函数完成，2.8后通过slaveof/5.0后通过replicaof 调用 PSYNC 函数完成。   
前者只能完整重同步，通过调用 slaveof 命令，主服务器（master）执行bgsave命令，并将bgsave命令期间的命令保存到一个缓冲区中（类似aof重写缓冲区），  
rdb文件保存完毕后，与从服务器（slave）建立连接（如果masterauth选项设置，连接需要验证），连接建立后，分两步完成复制：  
1、同步，从服务器flushdb后根据rdb文件初始化服务器，然后执行缓冲区内所有命令；  
2、传递命令，主服务器每执行一条命令都将它传递给从服务器执行一遍，以保证主服务器和从服务器的一致。（以上是SYNC干的事）  
以上的做法每次同步都要 bgsave 导致大量资源消耗（因为save本来就要遍历整个数据库）  

> Redis2.8后新增了 PSYNC 支持部分重同步，根据runid判断主从服务器是否曾经进行过复制而选择完整或部分重同步，  
然后维护一个 1MB 大小的复制积压缓冲区（内部为FIFO队列），保存主服务器执行过的所有命令，每个命令都有对应的偏移量（offset）  
当从服务器断连后重连，就可以根据两边的offset判断从服务器丢失的命令区间，将那个区间的命令发给从服务器就行，  
大大降低了开销，维持主从服务器连接需要心跳检测，查询“info replication”中lag字段为0或1则正常，>1则断连。  
>> 断线重连：  
1、runid不同，+FULLRESYNC<runid><offset>完整重同步；  
2、runid同，+CONTINUE<runid><offset>部分重同步；  
3、服务器版本低于2.8出错，-ERR。  
***  
分库分表：每种功能一个库/表。读写分离：主服务器写，从服务器读。  
  
    • Memcache和Redis了解
redis执行速度比memcache快，redis支持持久化而memcache不支持；  
redis支持5种数据对象而memcache只支持字符串；  
redis通过单线程串行化保证数据一致性，memcache通过CAS（check and set）保证并发一致性；  
redis支持主从复制，memcache支持一致性哈希。  
  
    • Redis的数据类型有哪些，底层怎么实现?
Redis有五种数据对象：string对象，list对象，hash对象，set对象，zset对象。
string字符串对象：SDS（简单动态字符串），embstr（特殊编码的字符串），int（整数值）    
list链表对象：linkedlist（双端链表），ziplist（压缩链表）  
hashtable哈希对象：dictht（字典），ziplist（压缩链表）  
set集合对象：intset（整数集合），dictht（字典）  
zset有序集合对象：skiplist（跳跃表），ziplist（压缩链表）  
使用“OBJECT ENCODING 键对象名”语句可以查询对应值对象的底层数据结构。  
  
    • Redis数据对象的编码转换
字符串对象：值为整数时用int，修改时转为raw；<32字节用embstr，embstr只读，所以修改也转为raw；  
链表对象：默认ziplist，元素个数>512或字符串对象>64字节用linkedlist；  
哈希对象：默认ziplist，元素个数>512或字符串对象>64字节用hashtable；  
集合对象：默认intset，元素个数>512或有非整数对象时用hashtable。  
有序集合对象：默认ziplist，元素个数>128或存在元素成员>64字节用skiplist。   
注：除了字符串对象，其它对象的上限值都可以通过修改配置文件中“对象名-max-编码方式-value/entries”字段修改。  

    • 请问Redis的rehash怎么做的，为什么要渐进rehash，渐进rehash又是怎么实现的
负载因子 load_factor = ht[0].used / ht[0].size。  
①当负载因子 >=1 且服务器没有执行 bgsave(RDB) / bgrewriteaof(AOF) 命令，rehash扩展。  
②当负载因子 >=5 且服务器正在执行 bgsave / bgrewriteaof 命令，rehash扩展。  
③当负载因子 <0.1 时，执行rehash收缩操作。  

扩展流程：  
1、为ht[1]分配空间，大小为最接近 ht[0].used \* 2 的 2n，如旧used为 15，最接近 15 \* 2 的就是 32；  
2、对ht[0]中每个键值对重新计算哈希值和索引值，放到ht[1]的table对应位置里面。  
3、所有键值对处理完毕后，把ht[1]改为ht[0]，创建新的ht[1]。  

缩减流程：为ht[1]分配空间，大小为第一个大于ht[0].used的2n，如旧used为12，最接近12的就是16。其他步骤类似。  
            
渐进性rehash：redis是单线程的，当数据量很大（千万/亿级）时，  
一次性将旧表中数据rehash可能会使服务器停止服务一段时间，所以分多次rehash来保持服务。  
1、为ht[1]分配空间，方法和上面一样；  
2、修改字典中rehashidx字段为0，表示rehash开始；（后续新的kv都会直接给到ht[1]，ht[0]到Step4的时候废弃）  
3、每次对字典进行增删查改操作时，将rehashidx对应的ht[0]中的键值对rehash到ht[1]中，并将rehashidx+1；  
4、一直到所有键值对rehash完成，将rehashidx设置回-1（初始值），表示rehash完成。  
> [美团团队的渐进式reharsh分享](https://tech.meituan.com/2018/07/27/redis-rehash-practice-optimization.html)
